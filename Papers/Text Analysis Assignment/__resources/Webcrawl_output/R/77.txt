Support The Guardian




The Guardian - Back to home








News



Opinion



Sport



Culture



Lifestyle




Menu







{{ #topLevelSections }}





{{ title }}


{{ #subSections }}


{{ title }}


{{ /subSections }}




{{ /topLevelSections }}


{{ #membershipLinks }}


{{ title }}


{{ /membershipLinks }}


Sign in/up






Switch edition



UK edition



US edition



Australia edition



International edition





{{ #secondarySections }}


{{ title }}


{{ /secondarySections }}















Elon Musk leads 116 experts calling for outright ban of killer robots








Open letter signed by Tesla chief and Alphabet’s Mustafa Suleyman urges UN to block use of lethal autonomous weapons to prevent third age of war




















A killer robot from the 2014 remake of Robocop. The open letter read: ‘lethal autonomous weapons will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend.’
Photograph: Allstar/Studio Canal/Sportsphoto Ltd./Allstar





Samuel Gibbs


Sun 20 Aug 2017 15.01 BST


Last modified on Mon 27 Nov 2017 18.17 GMT






Share on Facebook








Share on Twitter








Share via Email















View more sharing options



Share on LinkedIn








Share on Pinterest








Share on Google+








Share on WhatsApp








Share on Messenger














This article is over 7 months old




Some of the world’s leading robotics and artificial intelligence pioneers are calling on the United Nations to ban the development and use of killer robots.
Tesla’s Elon Musk and Alphabet’s Mustafa Suleyman are leading a group of 116 specialists from across 26 countries who are calling for the ban on autonomous weapons.
The UN recently voted to begin formal discussions on such weapons which include drones, tanks and automated machine guns. Ahead of this, the group of founders of AI and robotics companies have sent an open letter to the UN calling for it to prevent the arms race that is currently under way for killer robots. 
In their letter, the founders warn the review conference of the convention on conventional weapons that this arms race threatens to usher in the “third revolution in warfare” after gunpowder and nuclear arms.




The founders wrote: “Once developed, lethal autonomous weapons will permit armed conflict to be fought at a scale greater than ever, and at timescales faster than humans can comprehend. These can be weapons of terror, weapons that despots and terrorists use against innocent populations, and weapons hacked to behave in undesirable ways.
“We do not have long to act. Once this Pandora’s box is opened, it will be hard to close.”



Sorry, your browser is unable to play this video.
 Please
upgrade to a modern browser and try again.








In My Opinion: we should be more afraid of computers than we are


Experts have previously warned that AI technology has reached a point where the deployment of autonomous weapons is feasible within years, rather than decades. While AI can be used to make the battlefield a safer place for military personnel, experts fear that offensive weapons that operate on their own would lower the threshold of going to battle and result in greater loss of human life.
The letter, launching at the opening of the International Joint Conference on Artificial Intelligence (IJCAI) in Melbourne on Monday, has the backing of high-profile figures in the robotics field and strongly stresses the need for urgent action, after the UN was forced to delay a meeting that was due to start Monday to review the issue.




The founders call for “morally wrong” lethal autonomous weapons systems to be added to the list of weapons banned under the UN’s convention on certain conventional weapons (CCW) brought into force in 1983, which includes chemical and intentionally blinding laser weapons.
Toby Walsh, Scientia professor of artificial intelligence at the University of New South Wales in Sydney, said: “Nearly every technology can be used for good and bad, and artificial intelligence is no different. It can help tackle many of the pressing problems facing society today: inequality and poverty, the challenges posed by climate change and the ongoing global financial crisis. 
“However, the same technology can also be used in autonomous weapons to industrialise war. We need to make decisions today choosing which of these futures we want.”
Musk, one of the signatories of the open letter, has repeatedly warned for the need for pro-active regulation of AI, calling it humanity’s biggest existential threat, but while AI’s destructive potential is considered by some to be vast it is also thought be distant.




Ryan Gariepy, the founder of Clearpath Robotics said: “Unlike other potential manifestations of AI which still remain in the realm of science fiction, autonomous weapons systems are on the cusp of development right now and have a very real potential to cause significant harm to innocent people along with global instability.” 
This is not the first time the IJCAI, one of the world’s leading AI conferences, has been used as a platform to discuss lethal autonomous weapons systems. Two years ago the conference was used to launch an open letter signed by thousands of AI and robotics researchers including Musk and Stephen Hawking similarly calling for a ban, which helped push the UN into formal talks on the technologies.
The UK government opposed such a ban on lethal autonomous weapons in 2015, with the Foreign Office stating that “international humanitarian law already provides sufficient regulation for this area”. It said that the UK was not developing lethal autonomous weapons and that all weapons employed by UK armed forces would be “under human oversight and control”.
Science fiction or science fact?




  The T-800 from the Terminator film franchise. Photograph: Melinda Sue Gordon/Allstar/Paramount Pictures


While the suggestion of killer robots conjures images from science fiction such as the Terminator’s T-800 or Robocop’s ED-209, lethal autonomous weapons are already in use. Samsung’s SGR-A1 sentry gun, which is reportedly technically capable of firing autonomously but is disputed whether it is deployed as such, is in use along the South Korean border of the 2.5m-wide Korean Demilitarized Zone.




The fixed-place sentry gun, developed on behalf of the South Korean government, was the first of its kind with an autonomous system capable of performing surveillance, voice-recognition, tracking and firing with mounted machine gun or grenade launcher. But it is not the only autonomous weapon system in development, with prototypes available for land, air and sea combat.
The UK’s Taranis drone, in development by BAE Systems, is intended to be capable of carrying air-to-air and air-to-ground ordnance intercontinentally and incorporating full autonomy. The unmanned combat aerial vehicle, about the size of a BAE Hawk, the plane used by the Red Arrows, had its first test flight in 2013 and is expected to be operational some time after 2030 as part of the Royal Air Force’s Future Offensive Air System, destined to replace the human-piloted Tornado GR4 warplanes.
Russia, the US and other countries are currently developing robotic tanks that can either be remote controlled or operate autonomously. These projects range from autonomous versions of the Russian Uran-9 unmanned combat ground vehicle, to conventional tanks retrofitted with autonomous systems.




The US’s autonomous warship, the Sea Hunter built by Vigor Industrial, was launched in 2016 and, while still in development, is intended to have offensive capabilities including anti-submarine ordnance. Under the surface, Boeing’s autonomous submarine systems built on the Echo Voyager platform are also being considered for long-range deep-sea military use.
The Guardian view on robots as weapons: the human factor


Topics



Robots






Artificial intelligence (AI)



Elon Musk



Weapons technology



United Nations



news






Share on Facebook








Share on Twitter








Share via Email








Share on LinkedIn








Share on Pinterest








Share on Google+








Share on WhatsApp








Share on Messenger

























View on theguardian.com




{{#showContent}}


{{displayName}}

{{#description}}

{{description}}

{{/description}}
{{#content}}
{{#headline}}








{{#isVideo}}





{{/isVideo}}
{{#isGallery}}





{{/isGallery}}
{{#isAudio}}





{{/isAudio}}
{{#isComment}}





{{/isComment}}

{{headline}}

{{#isComment}}

{{byline}}

{{/isComment}}



{{#showWebPublicationDate}}






Published: 
{{webPublicationDate}}

{{/showWebPublicationDate}}



{{headline}}

{{/headline}}
{{/content}}

{{/showContent}}







More stories









More stories




{{#showContent}}


{{displayName}}

{{#description}}

{{description}}

{{/description}}
{{#content}}
{{#headline}}








{{#isVideo}}





{{/isVideo}}
{{#isGallery}}





{{/isGallery}}
{{#isAudio}}





{{/isAudio}}
{{#isComment}}





{{/isComment}}

{{headline}}

{{#isComment}}

{{byline}}

{{/isComment}}



{{#showWebPublicationDate}}






Published: 
{{webPublicationDate}}

{{/showWebPublicationDate}}



{{headline}}

{{/headline}}
{{/content}}

{{/showContent}}







More stories




{{#showContent}}


{{displayName}}

{{#description}}

{{description}}

{{/description}}
{{#content}}
{{#headline}}








{{#isVideo}}





{{/isVideo}}
{{#isGallery}}





{{/isGallery}}
{{#isAudio}}





{{/isAudio}}
{{#isComment}}





{{/isComment}}

{{headline}}

{{#isComment}}

{{byline}}

{{/isComment}}



{{#showWebPublicationDate}}






Published: 
{{webPublicationDate}}

{{/showWebPublicationDate}}



{{headline}}

{{/headline}}
{{/content}}

{{/showContent}}







More stories




{{#showContent}}


{{displayName}}

{{#description}}

{{description}}

{{/description}}
{{#content}}
{{#headline}}








{{#isVideo}}





{{/isVideo}}
{{#isGallery}}





{{/isGallery}}
{{#isAudio}}





{{/isAudio}}
{{#isComment}}





{{/isComment}}

{{headline}}

{{#isComment}}

{{byline}}

{{/isComment}}



{{#showWebPublicationDate}}






Published: 
{{webPublicationDate}}

{{/showWebPublicationDate}}



{{headline}}

{{/headline}}
{{/content}}

{{/showContent}}







More stories













back to top












become a supporter

make a contribution

securedrop

help


advertise with us

work for us

contact us

complaints & corrections


terms & conditions

privacy policy
cookie policy

digital newspaper archive


all topics

all contributors

Facebook

Twitter




© 2018 Guardian News and Media Limited or its affiliated companies. All rights reserved.