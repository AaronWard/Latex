 Next thing I want to try, is to implement some different RBMs (convolutional, gaussian, softmax) and maybe compare their results with autoencoders, because now I’m starting to favor RBMs more, perhaps just because of the beauty of the concept. They don’t even use backprop, how cool is that? I wonder if there are any attemps to discover similar positive-negative cycles in real neurons, which, of course, don’t have symmetric connections, but still may constitute the same kind of structures. Or, are real neurons tend to “settle down” and minimize their energy? Oh snap, now I’m going to google it for hours.